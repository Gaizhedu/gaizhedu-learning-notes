# 前言
这份笔记将记录有关该[项目](https://datawhalechina.github.io/llm-universe)的学习历程

## 1.1 大型语言模型（LLM）简介

首先什么是LLM，LLM指的是**大型语言模型**的简称

**Transformer**架构与2018年开始出现，其特点为通过大量文本数据来训练这些模型，使它们可以通过阅读大量文本来深入理解语言规则和模式

语言模型规模的扩大（增加模型大小或者使用更多的数据），模型可以展现出一些惊人的能力，使其在各种任务中都显著提升

获得大模型所经历的三个时期：预训练、后训练和在线推理

### 1.1.2.1 涌现能力

涌现能力是区分LLM和PLM最为显著的特征，常见的涌现能力有上下文学习，指令遵循以及逐步推理

## 1.2 什么是RAG

由于LLM在某些情况下人会出现无法提供准确的答案的情况，为了解决这一问题，便提出了一种新的模型架构：**检索增强生成**

这一功能整合了从庞大知识库中检索到的相关信息，并且由此为基础来指导大型语言模型生成更为精准的答案，从而显著提升回答的准确度与深度

### 1.2.1 RAG的工作流程

RAG的工作流程可以分为4个阶段，分别是数据处理，检索，增强和生成四个阶段

在数据处理阶段，先对原始数据进行清洗和处理，而后将处理后的数据转化为检索模型可以使用的格式，再讲处理后的数据存储到对应的数据库中。

检索阶段，将用户的问题输入到检索系统中，在数据库中检索相关信息

增强阶段，对检索的信息进行处理和增强，这是为了让生成模型可以更好地理解和使用

生成阶段，将增强后的信息输入到生成模型中，生成模型根据这些信息来生成答案

### 1.2.2 RAG和微调

在提升大语言模型效果中，RAG和微调是两个比较主流的方法

微调指是在特定的数据集上进一步训练语言模型，由此来提升模型在特定任务上的表现

## 1.3 LangChain

什么是LangChain呢？

简单来说，在ChatGPT成功的背景下，有大量的开发者急需利用OpenAI提供的API或者私有化模型来开发基于LLM的应用程序

虽然说LLM的调用比较简单，但是想要创建完整的应用程序，还是需要很复杂的工作，在此期间，有很多机构和开发者推出了大量的开源项目，旨在帮助开发者快速构建基于LLM的端到端应用程序

LangChain便是其中的一个项目

LangChain的目的是为各种LLM提供通用接口，从而简化应用程序的开发流程

### 1.3.1 LangChain的核心组件

LangChain主要由以下6个核心组件组成

模型输入、输出：与模型交互的接口

数据连接：与特定应用程序的数据进行交互的接口

链：将组件组合实现端到端应用

记忆：用于链的多次运行之间持久化应用程序状态

代理、回调：扩展模型的推理能力，用于复杂的应用的调用序列

在实际开发中，会根据自身需求灵活地进行组合

## 1.4 大模型开发

我们将开发**以大语言模型为功能核心、通过大语言模型的强大理解能力和生成能力、结合特殊的数据或业务逻辑来提供独特功能的应用**称为**大模型开发**。

一般通过调用API或开源模型来实现核心的理解与生成，通过Prompt Enginnering 来实现大语言模型的控制

传统的AI开发：

1. 依次拆解复杂业务逻辑
2. 对每个子业务构造训练数据与验证数据
3. 优化每个子业务训练的模型
4. 形成完整的模型链路来解决整个业务逻辑

大模型开发：

1. 用Prompt Engineering 来代替子模型的训练调优
2. 用Prompt链路组合来实现业务逻辑
3. 用一个通用大模型和若干业务Prompt来解决任务

可以看到，大模型开发相对于传统AI开发简洁了许多

